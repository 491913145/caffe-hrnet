name: "HRNet-w48"
layer {
    name: "data"
    type: "ImageSegData"
    top: "data"
    top: "label"
	top:"data_dim"
    include {
        phase: TRAIN
    }
    transform_param {
        mirror: true
        crop_size: 224
		scale_factors:0.5
		scale_factors:0.75
		scale_factors:0.1
		scale_factors:1.25
		scale_factors:1.5
		scale_factors:2
        mean_value: 103.94
        mean_value: 116.78
        mean_value: 123.68
		scale:0.017
    }
    image_data_param {
        batch_size:8
        source: "/data/train.txt"
        root_folder: "/data"
		shuffle:true
		label_type:PIXEL
    }
}
layer {
    bottom: "data"
    top: "conv1"
    name: "conv1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "conv1"
    top: "conv1_bn"
    name: "conv1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
	
}
layer {
    bottom: "conv1_bn"
    top: "conv1_bn"
    name: "conv1_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "conv1_bn"
    top: "conv2"
    name: "conv2"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "conv2"
    top: "conv2_bn"
    name: "conv2_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "conv2_bn"
    top: "conv2_bn"
    name: "conv2_bn/relu"
    type: "ReLU"
}
#stage1 4 bottleneck
layer {
    bottom: "conv2_bn"
    top: "s1_branch0_r0_0"
    name: "s1_branch0_r0_0"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r0_0"
    top: "s1_branch0_r0_0_bn"
    name: "s1_branch0_r0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "conv2_bn"
    top: "s1_branch0_r0_0_0"
    name: "s1_branch0_r0_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r0_0_0"
    top: "s1_branch0_r0_0_0_bn"
    name: "s1_branch0_r0_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_branch0_r0_0_0_bn"
    top: "s1_branch0_r0_0_0_bn"
    name: "s1_branch0_r0_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s1_branch0_r0_0_0_bn"
    top: "s1_branch0_r0_1"
    name: "s1_branch0_r0_1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r0_1"
    top: "s1_branch0_r0_1_bn"
    name: "s1_branch0_r0_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_branch0_r0_1_bn"
    top: "s1_branch0_r0_1_bn"
    name: "s1_branch0_r0_1_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s1_branch0_r0_1_bn"
    top: "s1_branch0_r0_2"
    name: "s1_branch0_r0_2"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r0_2"
    top: "s1_branch0_r0_2_bn"
    name: "s1_branch0_r0_2_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_branch0_r0_0_bn"
    bottom: "s1_branch0_r0_2_bn"
    top: "s1_branch0_r0_e0"
    name: "s1_branch0_r0_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s1_branch0_r0_e0"
    top: "s1_branch0_r0_e0"
    name: "s1_branch0_r0_e0/relu"
    type: "ReLU"
}

layer {
    bottom: "s1_branch0_r0_e0"
    top: "s1_branch0_r1_0_0"
    name: "s1_branch0_r1_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r1_0_0"
    top: "s1_branch0_r1_0_0_bn"
    name: "s1_branch0_r1_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_branch0_r1_0_0_bn"
    top: "s1_branch0_r1_0_0_bn"
    name: "s1_branch0_r1_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s1_branch0_r1_0_0_bn"
    top: "s1_branch0_r1_1"
    name: "s1_branch0_r1_1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r1_1"
    top: "s1_branch0_r1_1_bn"
    name: "s1_branch0_r1_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_branch0_r1_1_bn"
    top: "s1_branch0_r1_1_bn"
    name: "s1_branch0_r1_1_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s1_branch0_r1_1_bn"
    top: "s1_branch0_r1_2"
    name: "s1_branch0_r1_2"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r1_2"
    top: "s1_branch0_r1_2_bn"
    name: "s1_branch0_r1_2_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_branch0_r0_e0"
    bottom: "s1_branch0_r1_2_bn"
    top: "s1_branch0_r1_e0"
    name: "s1_branch0_r1_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s1_branch0_r1_e0"
    top: "s1_branch0_r1_e0"
    name: "s1_branch0_r1_e0/relu"
    type: "ReLU"
}

layer {
    bottom: "s1_branch0_r1_e0"
    top: "s1_branch0_r2_0_0"
    name: "s1_branch0_r2_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r2_0_0"
    top: "s1_branch0_r2_0_0_bn"
    name: "s1_branch0_r2_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_branch0_r2_0_0_bn"
    top: "s1_branch0_r2_0_0_bn"
    name: "s1_branch0_r2_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s1_branch0_r2_0_0_bn"
    top: "s1_branch0_r2_1"
    name: "s1_branch0_r2_1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r2_1"
    top: "s1_branch0_r2_1_bn"
    name: "s1_branch0_r2_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_branch0_r2_1_bn"
    top: "s1_branch0_r2_1_bn"
    name: "s1_branch0_r2_1_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s1_branch0_r2_1_bn"
    top: "s1_branch0_r2_2"
    name: "s1_branch0_r2_2"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r2_2"
    top: "s1_branch0_r2_2_bn"
    name: "s1_branch0_r2_2_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}

layer {
    bottom: "s1_branch0_r1_e0"
    bottom: "s1_branch0_r2_2_bn"
    top: "s1_branch0_r2_e0"
    name: "s1_branch0_r2_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s1_branch0_r2_e0"
    top: "s1_branch0_r2_e0"
    name: "s1_branch0_r2_e0/relu"
    type: "ReLU"
}

layer {
    bottom: "s1_branch0_r2_e0"
    top: "s1_branch0_r3_0_0"
    name: "s1_branch0_r3_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r3_0_0"
    top: "s1_branch0_r3_0_0_bn"
    name: "s1_branch0_r3_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_branch0_r3_0_0_bn"
    top: "s1_branch0_r3_0_0_bn"
    name: "s1_branch0_r3_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s1_branch0_r3_0_0_bn"
    top: "s1_branch0_r3_1"
    name: "s1_branch0_r3_1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r3_1"
    top: "s1_branch0_r3_1_bn"
    name: "s1_branch0_r3_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_branch0_r3_1_bn"
    top: "s1_branch0_r3_1_bn"
    name: "s1_branch0_r3_1_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s1_branch0_r3_1_bn"
    top: "s1_branch0_r3_2"
    name: "s1_branch0_r3_2"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_branch0_r3_2"
    top: "s1_branch0_r3_2_bn"
    name: "s1_branch0_r3_2_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}

layer {
    bottom: "s1_branch0_r2_e0"
    bottom: "s1_branch0_r3_2_bn"
    top: "s1_branch0_r3_e0"
    name: "s1_branch0_r3_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s1_branch0_r3_e0"
    top: "s1_branch0_r3_e0"
    name: "s1_branch0_r3_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s1_branch0_r3_e0"
    top: "s1_t1_branch0_0"
    name: "s1_t1_branch0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
        pad: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_t1_branch0_0"
    top: "s1_t1_branch0_0_bn"
    name: "s1_t1_branch0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_branch0_r3_e0"
    top: "s1_t1_branch1_0"
    name: "s1_t1_branch1_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
        pad: 1
		stride:2
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s1_t1_branch1_0"
    top: "s1_t1_branch1_0_bn"
    name: "s1_t1_branch1_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
#stage2 2branch 4 basic block
layer {
    bottom: "s1_t1_branch0_0_bn"
    top: "s2_branch0_r1_0_0"
    name: "s2_branch0_r1_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch0_r1_0_0"
    top: "s2_branch0_r1_0_0_bn"
    name: "s2_branch0_r1_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_branch0_r1_0_0_bn"
    top: "s2_branch0_r1_0_0_bn"
    name: "s2_branch0_r1_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch0_r1_0_0_bn"
    top: "s2_branch0_r1_1"
    name: "s2_branch0_r1_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch0_r1_1"
    top: "s2_branch0_r1_1_bn"
    name: "s2_branch0_r1_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_t1_branch0_0_bn"
    bottom: "s2_branch0_r1_1_bn"
    top: "s2_branch0_r1_e0"
    name: "s1_branch0_r1_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s2_branch0_r1_e0"
    top: "s2_branch0_r1_e0"
    name: "s2_branch0_r1_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch0_r1_e0"
    top: "s2_branch0_r2_0_0"
    name: "s2_branch0_r2_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch0_r2_0_0"
    top: "s2_branch0_r2_0_0_bn"
    name: "s2_branch0_r2_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_branch0_r2_0_0_bn"
    top: "s2_branch0_r2_0_0_bn"
    name: "s2_branch0_r2_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch0_r2_0_0_bn"
    top: "s2_branch0_r2_1"
    name: "s2_branch0_r2_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch0_r2_1"
    top: "s2_branch0_r2_1_bn"
    name: "s2_branch0_r2_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}

layer {
    bottom: "s2_branch0_r1_e0"
    bottom: "s2_branch0_r2_1_bn"
    top: "s2_branch0_r2_e0"
    name: "s1_branch0_r2_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s2_branch0_r2_e0"
    top: "s2_branch0_r2_e0"
    name: "s2_branch0_r2_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch0_r2_e0"
    top: "s2_branch0_r3_0_0"
    name: "s2_branch0_r3_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch0_r3_0_0"
    top: "s2_branch0_r3_0_0_bn"
    name: "s2_branch0_r3_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_branch0_r3_0_0_bn"
    top: "s2_branch0_r3_0_0_bn"
    name: "s2_branch0_r3_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch0_r3_0_0_bn"
    top: "s2_branch0_r3_1"
    name: "s2_branch0_r3_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch0_r3_1"
    top: "s2_branch0_r3_1_bn"
    name: "s2_branch0_r3_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_branch0_r2_e0"
    bottom: "s2_branch0_r3_1_bn"
    top: "s2_branch0_r3_e0"
    name: "s1_branch0_r3_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s2_branch0_r3_e0"
    top: "s2_branch0_r3_e0"
    name: "s2_branch0_r3_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch0_r3_e0"
    top: "s2_branch0_r4_0_0"
    name: "s2_branch0_r4_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch0_r4_0_0"
    top: "s2_branch0_r4_0_0_bn"
    name: "s2_branch0_r4_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_branch0_r4_0_0_bn"
    top: "s2_branch0_r4_0_0_bn"
    name: "s2_branch0_r4_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch0_r4_0_0_bn"
    top: "s2_branch0_r4_1"
    name: "s2_branch0_r4_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch0_r4_1"
    top: "s2_branch0_r4_1_bn"
    name: "s2_branch0_r4_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}

layer {
    bottom: "s2_branch0_r3_e0"
    bottom: "s2_branch0_r4_1_bn"
    top: "s2_branch0_r4_e0"
    name: "s1_branch0_r4_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s2_branch0_r4_e0"
    top: "s2_branch0_r4_e0"
    name: "s2_branch0_r4_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s1_t1_branch1_0_bn"
    top: "s2_branch1_r1_0_0"
    name: "s2_branch1_r1_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch1_r1_0_0"
    top: "s2_branch1_r1_0_0_bn"
    name: "s2_branch1_r1_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_branch1_r1_0_0_bn"
    top: "s2_branch1_r1_0_0_bn"
    name: "s2_branch1_r1_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch1_r1_0_0_bn"
    top: "s2_branch1_r1_1"
    name: "s2_branch1_r1_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch1_r1_1"
    top: "s2_branch1_r1_1_bn"
    name: "s2_branch1_r1_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s1_t1_branch1_0_bn"
    bottom: "s2_branch1_r1_1_bn"
    top: "s2_branch1_r1_e0"
    name: "s1_branch1_r1_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s2_branch1_r1_e0"
    top: "s2_branch1_r1_e0"
    name: "s2_branch1_r1_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch1_r1_e0"
    top: "s2_branch1_r2_0_0"
    name: "s2_branch1_r2_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch1_r2_0_0"
    top: "s2_branch1_r2_0_0_bn"
    name: "s2_branch1_r2_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_branch1_r2_0_0_bn"
    top: "s2_branch1_r2_0_0_bn"
    name: "s2_branch1_r2_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch1_r2_0_0_bn"
    top: "s2_branch1_r2_1"
    name: "s2_branch1_r2_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch1_r2_1"
    top: "s2_branch1_r2_1_bn"
    name: "s2_branch1_r2_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s2_branch1_r1_e0"
    bottom: "s2_branch1_r2_1_bn"
    top: "s2_branch1_r2_e0"
    name: "s1_branch1_r2_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s2_branch1_r2_e0"
    top: "s2_branch1_r2_e0"
    name: "s2_branch1_r2_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch1_r2_e0"
    top: "s2_branch1_r3_0_0"
    name: "s2_branch1_r3_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch1_r3_0_0"
    top: "s2_branch1_r3_0_0_bn"
    name: "s2_branch1_r3_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_branch1_r3_0_0_bn"
    top: "s2_branch1_r3_0_0_bn"
    name: "s2_branch1_r3_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch1_r3_0_0_bn"
    top: "s2_branch1_r3_1"
    name: "s2_branch1_r3_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch1_r3_1"
    top: "s2_branch1_r3_1_bn"
    name: "s2_branch1_r3_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_branch1_r2_e0"
    bottom: "s2_branch1_r3_1_bn"
    top: "s2_branch1_r3_e0"
    name: "s1_branch1_r3_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s2_branch1_r3_e0"
    top: "s2_branch1_r3_e0"
    name: "s2_branch1_r3_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch1_r3_e0"
    top: "s2_branch1_r4_0_0"
    name: "s2_branch1_r4_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch1_r4_0_0"
    top: "s2_branch1_r4_0_0_bn"
    name: "s2_branch1_r4_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_branch1_r4_0_0_bn"
    top: "s2_branch1_r4_0_0_bn"
    name: "s2_branch1_r4_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch1_r4_0_0_bn"
    top: "s2_branch1_r4_1"
    name: "s2_branch1_r4_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_branch1_r4_1"
    top: "s2_branch1_r4_1_bn"
    name: "s2_branch1_r4_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}

layer {
    bottom: "s2_branch1_r3_e0"
    bottom: "s2_branch1_r4_1_bn"
    top: "s2_branch1_r4_e0"
    name: "s1_branch1_r4_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s2_branch1_r4_e0"
    top: "s2_branch1_r4_e0"
    name: "s2_branch1_r4_e0/relu"
    type: "ReLU"
}
#transform2
layer {
    bottom: "s2_branch1_r4_e0"
    top: "s2_t1_branch0_0"
    name: "s2_t1_branch0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_t1_branch0_0"
    top: "s2_t1_branch0_0_bn"
    name: "s2_t1_branch0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_t1_branch0_0_bn"
    top: "s2_t1_branch0_0_bn_up2"
    name: "s2_t1_branch0_0_bn_up2"
    type: "Interp"
	interp_param{
		zoom_factor:2
		pad_beg:0
		pad_end:0
	}
}
layer {
    bottom: "s2_branch0_r4_e0"
    bottom: "s2_t1_branch0_0_bn_up2"
    top: "s2_t0_branch0_e0"
    name: "s2_t0_branch0_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s2_t0_branch0_e0"
    top: "s2_t0_branch0_e0"
    name: "s2_t0_branch0_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_branch0_r4_e0"
    top: "s2_t1_branch0_1"
    name: "s2_t1_branch0_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		stride:2
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_t1_branch0_1"
    top: "s2_t1_branch0_1_bn"
    name: "s2_t1_branch0_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_branch1_r4_e0"
    bottom: "s2_t1_branch0_1_bn"
    top: "s2_t1_branch1_e0"
    name: "s2_t1_branch1_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s2_t1_branch1_e0"
    top: "s2_t1_branch1_e0"
    name: "s2_t1_branch1_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_t1_branch1_e0"
    top: "s2_t2_branch0_0"
    name: "s2_t2_branch0_0"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		stride:2
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s2_t2_branch0_0"
    top: "s2_t2_branch0_0_bn"
    name: "s2_t2_branch0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_t2_branch0_0_bn"
    top: "s2_t2_branch0_0_bn"
    name: "s2_t2_branch0_0_bn/relu"
    type: "ReLU"
}
#stage3
layer {
    bottom: "s2_t0_branch0_e0"
    top: "s3_branch0_r1_0_0"
    name: "s3_branch0_r1_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch0_r1_0_0"
    top: "s3_branch0_r1_0_0_bn"
    name: "s3_branch0_r1_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch0_r1_0_0_bn"
    top: "s3_branch0_r1_0_0_bn"
    name: "s3_branch0_r1_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch0_r1_0_0_bn"
    top: "s3_branch0_r1_1"
    name: "s3_branch0_r1_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch0_r1_1"
    top: "s3_branch0_r1_1_bn"
    name: "s3_branch0_r1_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s2_t0_branch0_e0"
    bottom: "s3_branch0_r1_1_bn"
    top: "s3_branch0_r1_e0"
    name: "s1_branch0_r1_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch0_r1_e0"
    top: "s3_branch0_r1_e0"
    name: "s3_branch0_r1_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch0_r1_e0"
    top: "s3_branch0_r2_0_0"
    name: "s3_branch0_r2_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch0_r2_0_0"
    top: "s3_branch0_r2_0_0_bn"
    name: "s3_branch0_r2_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch0_r2_0_0_bn"
    top: "s3_branch0_r2_0_0_bn"
    name: "s3_branch0_r2_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch0_r2_0_0_bn"
    top: "s3_branch0_r2_1"
    name: "s3_branch0_r2_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch0_r2_1"
    top: "s3_branch0_r2_1_bn"
    name: "s3_branch0_r2_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch0_r1_e0"
    bottom: "s3_branch0_r2_1_bn"
    top: "s3_branch0_r2_e0"
    name: "s1_branch0_r2_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch0_r2_e0"
    top: "s3_branch0_r2_e0"
    name: "s3_branch0_r2_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch0_r2_e0"
    top: "s3_branch0_r3_0_0"
    name: "s3_branch0_r3_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch0_r3_0_0"
    top: "s3_branch0_r3_0_0_bn"
    name: "s3_branch0_r3_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch0_r3_0_0_bn"
    top: "s3_branch0_r3_0_0_bn"
    name: "s3_branch0_r3_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch0_r3_0_0_bn"
    top: "s3_branch0_r3_1"
    name: "s3_branch0_r3_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch0_r3_1"
    top: "s3_branch0_r3_1_bn"
    name: "s3_branch0_r3_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}

layer {
    bottom: "s3_branch0_r2_e0"
    bottom: "s3_branch0_r3_1_bn"
    top: "s3_branch0_r3_e0"
    name: "s1_branch0_r3_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch0_r3_e0"
    top: "s3_branch0_r3_e0"
    name: "s3_branch0_r3_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch0_r3_e0"
    top: "s3_branch0_r4_0_0"
    name: "s3_branch0_r4_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch0_r4_0_0"
    top: "s3_branch0_r4_0_0_bn"
    name: "s3_branch0_r4_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch0_r4_0_0_bn"
    top: "s3_branch0_r4_0_0_bn"
    name: "s3_branch0_r4_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch0_r4_0_0_bn"
    top: "s3_branch0_r4_1"
    name: "s3_branch0_r4_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch0_r4_1"
    top: "s3_branch0_r4_1_bn"
    name: "s3_branch0_r4_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch0_r3_e0"
    bottom: "s3_branch0_r4_1_bn"
    top: "s3_branch0_r4_e0"
    name: "s1_branch0_r4_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch0_r4_e0"
    top: "s3_branch0_r4_e0"
    name: "s3_branch0_r4_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_t1_branch1_e0"
    top: "s3_branch1_r1_0_0"
    name: "s3_branch1_r1_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch1_r1_0_0"
    top: "s3_branch1_r1_0_0_bn"
    name: "s3_branch1_r1_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch1_r1_0_0_bn"
    top: "s3_branch1_r1_0_0_bn"
    name: "s3_branch1_r1_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch1_r1_0_0_bn"
    top: "s3_branch1_r1_1"
    name: "s3_branch1_r1_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch1_r1_1"
    top: "s3_branch1_r1_1_bn"
    name: "s3_branch1_r1_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}

layer {
    bottom: "s2_t1_branch1_e0"
    bottom: "s3_branch1_r1_1_bn"
    top: "s3_branch1_r1_e0"
    name: "s1_branch1_r1_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch1_r1_e0"
    top: "s3_branch1_r1_e0"
    name: "s3_branch1_r1_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch1_r1_e0"
    top: "s3_branch1_r2_0_0"
    name: "s3_branch1_r2_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch1_r2_0_0"
    top: "s3_branch1_r2_0_0_bn"
    name: "s3_branch1_r2_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch1_r2_0_0_bn"
    top: "s3_branch1_r2_0_0_bn"
    name: "s3_branch1_r2_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch1_r2_0_0_bn"
    top: "s3_branch1_r2_1"
    name: "s3_branch1_r2_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch1_r2_1"
    top: "s3_branch1_r2_1_bn"
    name: "s3_branch1_r2_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch1_r2_1_bn"
    top: "s3_branch1_r2_1_bn"
    name: "s3_branch1_r2_1_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch1_r1_e0"
    bottom: "s3_branch1_r2_1_bn"
    top: "s3_branch1_r2_e0"
    name: "s1_branch1_r2_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch1_r2_e0"
    top: "s3_branch1_r2_e0"
    name: "s3_branch1_r2_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch1_r2_e0"
    top: "s3_branch1_r3_0_0"
    name: "s3_branch1_r3_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch1_r3_0_0"
    top: "s3_branch1_r3_0_0_bn"
    name: "s3_branch1_r3_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch1_r3_0_0_bn"
    top: "s3_branch1_r3_0_0_bn"
    name: "s3_branch1_r3_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch1_r3_0_0_bn"
    top: "s3_branch1_r3_1"
    name: "s3_branch1_r3_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch1_r3_1"
    top: "s3_branch1_r3_1_bn"
    name: "s3_branch1_r3_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}

layer {
    bottom: "s3_branch1_r2_e0"
    bottom: "s3_branch1_r3_1_bn"
    top: "s3_branch1_r3_e0"
    name: "s1_branch1_r3_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch1_r3_e0"
    top: "s3_branch1_r3_e0"
    name: "s3_branch1_r3_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch1_r3_e0"
    top: "s3_branch1_r4_0_0"
    name: "s3_branch1_r4_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch1_r4_0_0"
    top: "s3_branch1_r4_0_0_bn"
    name: "s3_branch1_r4_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch1_r4_0_0_bn"
    top: "s3_branch1_r4_0_0_bn"
    name: "s3_branch1_r4_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch1_r4_0_0_bn"
    top: "s3_branch1_r4_1"
    name: "s3_branch1_r4_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch1_r4_1"
    top: "s3_branch1_r4_1_bn"
    name: "s3_branch1_r4_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}

layer {
    bottom: "s3_branch1_r3_e0"
    bottom: "s3_branch1_r4_1_bn"
    top: "s3_branch1_r4_e0"
    name: "s1_branch1_r4_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch1_r4_e0"
    top: "s3_branch1_r4_e0"
    name: "s3_branch1_r4_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s2_t2_branch0_0_bn"
    top: "s3_branch2_r1_0_0"
    name: "s3_branch2_r1_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch2_r1_0_0"
    top: "s3_branch2_r1_0_0_bn"
    name: "s3_branch2_r1_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch2_r1_0_0_bn"
    top: "s3_branch2_r1_0_0_bn"
    name: "s3_branch2_r1_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch2_r1_0_0_bn"
    top: "s3_branch2_r1_1"
    name: "s3_branch2_r1_1"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch2_r1_1"
    top: "s3_branch2_r1_1_bn"
    name: "s3_branch2_r1_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}

layer {
    bottom: "s2_t2_branch0_0_bn"
    bottom: "s3_branch2_r1_1_bn"
    top: "s3_branch2_r1_e0"
    name: "s1_branch2_r1_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch2_r1_e0"
    top: "s3_branch2_r1_e0"
    name: "s3_branch2_r1_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch2_r1_e0"
    top: "s3_branch2_r2_0_0"
    name: "s3_branch2_r2_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch2_r2_0_0"
    top: "s3_branch2_r2_0_0_bn"
    name: "s3_branch2_r2_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch2_r2_0_0_bn"
    top: "s3_branch2_r2_0_0_bn"
    name: "s3_branch2_r2_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch2_r2_0_0_bn"
    top: "s3_branch2_r2_1"
    name: "s3_branch2_r2_1"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch2_r2_1"
    top: "s3_branch2_r2_1_bn"
    name: "s3_branch2_r2_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}

layer {
    bottom: "s3_branch2_r1_e0"
    bottom: "s3_branch2_r2_1_bn"
    top: "s3_branch2_r2_e0"
    name: "s1_branch2_r2_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch2_r2_e0"
    top: "s3_branch2_r2_e0"
    name: "s3_branch2_r2_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch2_r2_e0"
    top: "s3_branch2_r3_0_0"
    name: "s3_branch2_r3_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch2_r3_0_0"
    top: "s3_branch2_r3_0_0_bn"
    name: "s3_branch2_r3_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s3_branch2_r3_0_0_bn"
    top: "s3_branch2_r3_0_0_bn"
    name: "s3_branch2_r3_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch2_r3_0_0_bn"
    top: "s3_branch2_r3_1"
    name: "s3_branch2_r3_1"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch2_r3_1"
    top: "s3_branch2_r3_1_bn"
    name: "s3_branch2_r3_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s3_branch2_r3_1_bn"
    top: "s3_branch2_r3_1_bn"
    name: "s3_branch2_r3_1_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch2_r2_e0"
    bottom: "s3_branch2_r3_1_bn"
    top: "s3_branch2_r3_e0"
    name: "s1_branch2_r3_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch2_r3_e0"
    top: "s3_branch2_r3_e0"
    name: "s3_branch2_r3_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch2_r3_e0"
    top: "s3_branch2_r4_0_0"
    name: "s3_branch2_r4_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch2_r4_0_0"
    top: "s3_branch2_r4_0_0_bn"
    name: "s3_branch2_r4_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s3_branch2_r4_0_0_bn"
    top: "s3_branch2_r4_0_0_bn"
    name: "s3_branch2_r4_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch2_r4_0_0_bn"
    top: "s3_branch2_r4_1"
    name: "s3_branch2_r4_1"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_branch2_r4_1"
    top: "s3_branch2_r4_1_bn"
    name: "s3_branch2_r4_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s3_branch2_r4_1_bn"
    top: "s3_branch2_r4_1_bn"
    name: "s3_branch2_r4_1_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch2_r3_e0"
    bottom: "s3_branch2_r4_1_bn"
    top: "s3_branch2_r4_e0"
    name: "s1_branch2_r4_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch2_r4_e0"
    top: "s3_branch2_r4_e0"
    name: "s3_branch2_r4_e0/relu"
    type: "ReLU"
}
#transform3
layer {
    bottom: "s3_branch1_r4_e0"
    top: "s3_t0_branch0_1"
    name: "s3_t0_branch0_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_t0_branch0_1"
    top: "s3_t0_branch0_1_bn"
    name: "s3_t0_branch0_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}

layer {
    bottom: "s3_t0_branch0_1_bn"
    top: "s3_t0_branch0_1_bn_up2"
    name: "s3_t0_branch0_1_bn_up2"
    type: "Interp"
    interp_param {
        zoom_factor: 2
		pad_beg:0
		pad_end:0
    }
}
layer {
    bottom: "s3_branch2_r4_e0"
    top: "s3_t0_branch0_2"
    name: "s3_t0_branch0_2"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_t0_branch0_2"
    top: "s3_t0_branch0_2_bn"
    name: "s3_t0_branch0_2_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}

layer {
    bottom: "s3_t0_branch0_2_bn"
    top: "s3_t0_branch0_2_bn_up4"
    name: "s3_t0_branch0_2_bn_up4"
    type: "Interp"
    interp_param {
        zoom_factor: 4
		pad_beg:0
		pad_end:0
    }
}
layer {
    bottom: "s3_branch0_r4_e0"
    bottom: "s3_t0_branch0_1_bn_up2"
    bottom: "s3_t0_branch0_2_bn_up4"
    top: "s3_branch0_e0"
    name: "s3_branch0_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch0_e0"
    top: "s3_branch0_e0"
    name: "s3_branch0_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch0_r4_e0"
    top: "s3_t1_branch1_0"
    name: "s3_t1_branch1_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		stride:2
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_t1_branch1_0"
    top: "s3_t1_branch1_0_bn"
    name: "s3_t1_branch1_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}

layer {
    bottom: "s3_branch2_r4_e0"
    top: "s3_t1_branch1_2"
    name: "s3_t1_branch1_2"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		stride:2
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_t1_branch1_2"
    top: "s3_t1_branch1_2_bn"
    name: "s3_t1_branch1_2_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}

layer {
    bottom: "s3_t1_branch1_2_bn"
    top: "s3_t1_branch1_2_bn_up2"
    name: "s3_t1_branch1_2_bn_up2"
    type: "Interp"
    interp_param {
        zoom_factor: 2
		pad_beg:0
		pad_end:0
    }
}
layer {
    bottom: "s3_t1_branch1_0_bn"
    bottom: "s3_branch1_r4_e0"
    bottom: "s3_t1_branch1_2_bn_up2"
    top: "s3_branch1_e0"
    name: "s3_branch1_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch1_e0"
    top: "s3_branch1_e0"
    name: "s3_branch1_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch0_r4_e0"
    top: "s3_t2_branch2_0"
    name: "s3_t2_branch2_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		stride:2
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_t2_branch2_0"
    top: "s3_t2_branch2_0_bn"
    name: "s3_t2_branch2_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s3_t2_branch2_0_bn"
    top: "s3_t2_branch2_0_1"
    name: "s3_t2_branch2_0_1"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		stride:2
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_t2_branch2_0_1"
    top: "s3_t2_branch2_0_1_bn"
    name: "s3_t2_branch2_0_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}

layer {
    bottom: "s3_branch1_r4_e0"
    top: "s3_t2_branch2_1"
    name: "s3_t2_branch2_1"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		stride:2
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_t2_branch2_1"
    top: "s3_t2_branch2_1_bn"
    name: "s3_t2_branch2_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}

layer {
    bottom: "s3_t2_branch2_0_1_bn"
    bottom: "s3_t2_branch2_1_bn"
    bottom: "s3_branch2_r4_e0"
    top: "s3_branch3_e0"
    name: "s3_branch3_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s3_branch3_e0"
    top: "s3_branch3_e0"
    name: "s3_branch3_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch3_e0"
    top: "s3_t3_branch3_0"
    name: "s3_t3_branch3_0"
    type: "Convolution"
    convolution_param {
        num_output: 384
        kernel_size: 3
		stride:2
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s3_t3_branch3_0"
    top: "s3_t3_branch3_0_bn"
    name: "s3_t3_branch3_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s3_t3_branch3_0_bn"
    top: "s3_t3_branch3_0_bn"
    name: "s3_t3_branch3_0_bn/relu"
    type: "ReLU"
}
#stage4
layer {
    bottom: "s3_branch0_e0"
    top: "s4_branch0_r1_0_0"
    name: "s4_branch0_r1_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch0_r1_0_0"
    top: "s4_branch0_r1_0_0_bn"
    name: "s4_branch0_r1_0_0_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s4_branch0_r1_0_0_bn"
    top: "s4_branch0_r1_0_0_bn"
    name: "s4_branch0_r1_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch0_r1_0_0_bn"
    top: "s4_branch0_r1_1"
    name: "s4_branch0_r1_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch0_r1_1"
    top: "s4_branch0_r1_1_bn"
    name: "s4_branch0_r1_1_bn"
    type: "CuDNNBatchNorm"
	cudnn_batch_norm_param{
		scale_filler{
			type:"constant"
			value:1
		}
		bias_filler{
			type:"constant"
			value:0
		}
	frozen:false
	}
}
layer {
    bottom: "s3_branch0_e0"
    bottom: "s4_branch0_r1_1_bn"
    top: "s4_branch0_r1_e0"
    name: "s1_branch2_r1_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch0_r1_e0"
    top: "s4_branch0_r1_e0"
    name: "s4_branch0_r1_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch0_r1_e0"
    top: "s4_branch0_r2_0_0"
    name: "s4_branch0_r2_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch0_r2_0_0"
    top: "s4_branch0_r2_0_0_bn"
    name: "s4_branch0_r2_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch0_r2_0_0_bn"
    top: "s4_branch0_r2_0_0_bn"
    name: "s4_branch0_r2_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch0_r2_0_0_bn"
    top: "s4_branch0_r2_1"
    name: "s4_branch0_r2_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch0_r2_1"
    top: "s4_branch0_r2_1_bn"
    name: "s4_branch0_r2_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch0_r1_e0"
    bottom: "s4_branch0_r2_1_bn"
    top: "s4_branch0_r2_e0"
    name: "s1_branch2_r2_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch0_r2_e0"
    top: "s4_branch0_r2_e0"
    name: "s4_branch0_r2_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch0_r2_e0"
    top: "s4_branch0_r3_0_0"
    name: "s4_branch0_r3_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch0_r3_0_0"
    top: "s4_branch0_r3_0_0_bn"
    name: "s4_branch0_r3_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch0_r3_0_0_bn"
    top: "s4_branch0_r3_0_0_bn"
    name: "s4_branch0_r3_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch0_r3_0_0_bn"
    top: "s4_branch0_r3_1"
    name: "s4_branch0_r3_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch0_r3_1"
    top: "s4_branch0_r3_1_bn"
    name: "s4_branch0_r3_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch0_r2_e0"
    bottom: "s4_branch0_r3_1_bn"
    top: "s4_branch0_r3_e0"
    name: "s1_branch2_r3_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch0_r3_e0"
    top: "s4_branch0_r3_e0"
    name: "s4_branch0_r3_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch0_r3_e0"
    top: "s4_branch0_r4_0_0"
    name: "s4_branch0_r4_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch0_r4_0_0"
    top: "s4_branch0_r4_0_0_bn"
    name: "s4_branch0_r4_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch0_r4_0_0_bn"
    top: "s4_branch0_r4_0_0_bn"
    name: "s4_branch0_r4_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch0_r4_0_0_bn"
    top: "s4_branch0_r4_1"
    name: "s4_branch0_r4_1"
    type: "Convolution"
    convolution_param {
        num_output: 48
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch0_r4_1"
    top: "s4_branch0_r4_1_bn"
    name: "s4_branch0_r4_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch0_r3_e0"
    bottom: "s4_branch0_r4_1_bn"
    top: "s4_branch0_r4_e0"
    name: "s1_branch2_r4_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch0_r4_e0"
    top: "s4_branch0_r4_e0"
    name: "s4_branch0_r4_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch1_e0"
    top: "s4_branch1_r1_0_0"
    name: "s4_branch1_r1_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch1_r1_0_0"
    top: "s4_branch1_r1_0_0_bn"
    name: "s4_branch1_r1_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch1_r1_0_0_bn"
    top: "s4_branch1_r1_0_0_bn"
    name: "s4_branch1_r1_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch1_r1_0_0_bn"
    top: "s4_branch1_r1_1"
    name: "s4_branch1_r1_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch1_r1_1"
    top: "s4_branch1_r1_1_bn"
    name: "s4_branch1_r1_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s3_branch1_e0"
    bottom: "s4_branch1_r1_1_bn"
    top: "s4_branch1_r1_e0"
    name: "s1_branch2_r1_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch1_r1_e0"
    top: "s4_branch1_r1_e0"
    name: "s4_branch1_r1_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch1_r1_e0"
    top: "s4_branch1_r2_0_0"
    name: "s4_branch1_r2_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch1_r2_0_0"
    top: "s4_branch1_r2_0_0_bn"
    name: "s4_branch1_r2_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch1_r2_0_0_bn"
    top: "s4_branch1_r2_0_0_bn"
    name: "s4_branch1_r2_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch1_r2_0_0_bn"
    top: "s4_branch1_r2_1"
    name: "s4_branch1_r2_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch1_r2_1"
    top: "s4_branch1_r2_1_bn"
    name: "s4_branch1_r2_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch1_r1_e0"
    bottom: "s4_branch1_r2_1_bn"
    top: "s4_branch1_r2_e0"
    name: "s1_branch2_r2_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch1_r2_e0"
    top: "s4_branch1_r2_e0"
    name: "s4_branch1_r2_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch1_r2_e0"
    top: "s4_branch1_r3_0_0"
    name: "s4_branch1_r3_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch1_r3_0_0"
    top: "s4_branch1_r3_0_0_bn"
    name: "s4_branch1_r3_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch1_r3_0_0_bn"
    top: "s4_branch1_r3_0_0_bn"
    name: "s4_branch1_r3_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch1_r3_0_0_bn"
    top: "s4_branch1_r3_1"
    name: "s4_branch1_r3_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch1_r3_1"
    top: "s4_branch1_r3_1_bn"
    name: "s4_branch1_r3_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch1_r2_e0"
    bottom: "s4_branch1_r3_1_bn"
    top: "s4_branch1_r3_e0"
    name: "s1_branch2_r3_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch1_r3_e0"
    top: "s4_branch1_r3_e0"
    name: "s4_branch1_r3_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch1_r3_e0"
    top: "s4_branch1_r4_0_0"
    name: "s4_branch1_r4_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch1_r4_0_0"
    top: "s4_branch1_r4_0_0_bn"
    name: "s4_branch1_r4_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch1_r4_0_0_bn"
    top: "s4_branch1_r4_0_0_bn"
    name: "s4_branch1_r4_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch1_r4_0_0_bn"
    top: "s4_branch1_r4_1"
    name: "s4_branch1_r4_1"
    type: "Convolution"
    convolution_param {
        num_output: 96
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch1_r4_1"
    top: "s4_branch1_r4_1_bn"
    name: "s4_branch1_r4_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch1_r3_e0"
    bottom: "s4_branch1_r4_1_bn"
    top: "s4_branch1_r4_e0"
    name: "s1_branch2_r4_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch1_r4_e0"
    top: "s4_branch1_r4_e0"
    name: "s4_branch1_r4_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_branch3_e0"
    top: "s4_branch2_r1_0_0"
    name: "s4_branch2_r1_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch2_r1_0_0"
    top: "s4_branch2_r1_0_0_bn"
    name: "s4_branch2_r1_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch2_r1_0_0_bn"
    top: "s4_branch2_r1_0_0_bn"
    name: "s4_branch2_r1_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch2_r1_0_0_bn"
    top: "s4_branch2_r1_1"
    name: "s4_branch2_r1_1"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch2_r1_1"
    top: "s4_branch2_r1_1_bn"
    name: "s4_branch2_r1_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s3_branch3_e0"
    bottom: "s4_branch2_r1_1_bn"
    top: "s4_branch2_r1_e0"
    name: "s1_branch2_r1_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch2_r1_e0"
    top: "s4_branch2_r1_e0"
    name: "s4_branch2_r1_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch2_r1_e0"
    top: "s4_branch2_r2_0_0"
    name: "s4_branch2_r2_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch2_r2_0_0"
    top: "s4_branch2_r2_0_0_bn"
    name: "s4_branch2_r2_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch2_r2_0_0_bn"
    top: "s4_branch2_r2_0_0_bn"
    name: "s4_branch2_r2_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch2_r2_0_0_bn"
    top: "s4_branch2_r2_1"
    name: "s4_branch2_r2_1"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch2_r2_1"
    top: "s4_branch2_r2_1_bn"
    name: "s4_branch2_r2_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch2_r1_e0"
    bottom: "s4_branch2_r2_1_bn"
    top: "s4_branch2_r2_e0"
    name: "s1_branch2_r2_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch2_r2_e0"
    top: "s4_branch2_r2_e0"
    name: "s4_branch2_r2_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch2_r2_e0"
    top: "s4_branch2_r3_0_0"
    name: "s4_branch2_r3_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch2_r3_0_0"
    top: "s4_branch2_r3_0_0_bn"
    name: "s4_branch2_r3_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch2_r3_0_0_bn"
    top: "s4_branch2_r3_0_0_bn"
    name: "s4_branch2_r3_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch2_r3_0_0_bn"
    top: "s4_branch2_r3_1"
    name: "s4_branch2_r3_1"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch2_r3_1"
    top: "s4_branch2_r3_1_bn"
    name: "s4_branch2_r3_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch2_r2_e0"
    bottom: "s4_branch2_r3_1_bn"
    top: "s4_branch2_r3_e0"
    name: "s1_branch2_r3_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch2_r3_e0"
    top: "s4_branch2_r3_e0"
    name: "s4_branch2_r3_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch2_r3_e0"
    top: "s4_branch2_r4_0_0"
    name: "s4_branch2_r4_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch2_r4_0_0"
    top: "s4_branch2_r4_0_0_bn"
    name: "s4_branch2_r4_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch2_r4_0_0_bn"
    top: "s4_branch2_r4_0_0_bn"
    name: "s4_branch2_r4_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch2_r4_0_0_bn"
    top: "s4_branch2_r4_1"
    name: "s4_branch2_r4_1"
    type: "Convolution"
    convolution_param {
        num_output: 192
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch2_r4_1"
    top: "s4_branch2_r4_1_bn"
    name: "s4_branch2_r4_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch2_r3_e0"
    bottom: "s4_branch2_r4_1_bn"
    top: "s4_branch2_r4_e0"
    name: "s1_branch2_r4_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch2_r4_e0"
    top: "s4_branch2_r4_e0"
    name: "s4_branch2_r4_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s3_t3_branch3_0_bn"
    top: "s4_branch3_r1_0_0"
    name: "s4_branch3_r1_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 384
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch3_r1_0_0"
    top: "s4_branch3_r1_0_0_bn"
    name: "s4_branch3_r1_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch3_r1_0_0_bn"
    top: "s4_branch3_r1_0_0_bn"
    name: "s4_branch3_r1_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch3_r1_0_0_bn"
    top: "s4_branch3_r1_1"
    name: "s4_branch3_r1_1"
    type: "Convolution"
    convolution_param {
        num_output: 384
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch3_r1_1"
    top: "s4_branch3_r1_1_bn"
    name: "s4_branch3_r1_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s3_t3_branch3_0_bn"
    bottom: "s4_branch3_r1_1_bn"
    top: "s4_branch3_r1_e0"
    name: "s1_branch3_r1_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch3_r1_e0"
    top: "s4_branch3_r1_e0"
    name: "s4_branch3_r1_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch3_r1_e0"
    top: "s4_branch3_r2_0_0"
    name: "s4_branch3_r2_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 384
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch3_r2_0_0"
    top: "s4_branch3_r2_0_0_bn"
    name: "s4_branch3_r2_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch3_r2_0_0_bn"
    top: "s4_branch3_r2_0_0_bn"
    name: "s4_branch3_r2_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch3_r2_0_0_bn"
    top: "s4_branch3_r2_1"
    name: "s4_branch3_r2_1"
    type: "Convolution"
    convolution_param {
        num_output: 384
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch3_r2_1"
    top: "s4_branch3_r2_1_bn"
    name: "s4_branch3_r2_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch3_r1_e0"
    bottom: "s4_branch3_r2_1_bn"
    top: "s4_branch3_r2_e0"
    name: "s1_branch3_r2_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch3_r2_e0"
    top: "s4_branch3_r2_e0"
    name: "s4_branch3_r2_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch3_r2_e0"
    top: "s4_branch3_r3_0_0"
    name: "s4_branch3_r3_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 384
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch3_r3_0_0"
    top: "s4_branch3_r3_0_0_bn"
    name: "s4_branch3_r3_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch3_r3_0_0_bn"
    top: "s4_branch3_r3_0_0_bn"
    name: "s4_branch3_r3_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch3_r3_0_0_bn"
    top: "s4_branch3_r3_1"
    name: "s4_branch3_r3_1"
    type: "Convolution"
    convolution_param {
        num_output: 384
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch3_r3_1"
    top: "s4_branch3_r3_1_bn"
    name: "s4_branch3_r3_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch3_r2_e0"
    bottom: "s4_branch3_r3_1_bn"
    top: "s4_branch3_r3_e0"
    name: "s1_branch3_r3_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch3_r3_e0"
    top: "s4_branch3_r3_e0"
    name: "s4_branch3_r3_e0/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch3_r3_e0"
    top: "s4_branch3_r4_0_0"
    name: "s4_branch3_r4_0_0"
    type: "Convolution"
    convolution_param {
        num_output: 384
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch3_r4_0_0"
    top: "s4_branch3_r4_0_0_bn"
    name: "s4_branch3_r4_0_0_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch3_r4_0_0_bn"
    top: "s4_branch3_r4_0_0_bn"
    name: "s4_branch3_r4_0_0_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "s4_branch3_r4_0_0_bn"
    top: "s4_branch3_r4_1"
    name: "s4_branch3_r4_1"
    type: "Convolution"
    convolution_param {
        num_output: 384
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "s4_branch3_r4_1"
    top: "s4_branch3_r4_1_bn"
    name: "s4_branch3_r4_1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "s4_branch3_r3_e0"
    bottom: "s4_branch3_r4_1_bn"
    top: "s4_branch3_r4_e0"
    name: "s1_branch3_r4_e0"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}
layer {
    bottom: "s4_branch3_r4_e0"
    top: "s4_branch3_r4_e0"
    name: "s4_branch3_r4_e0/relu"
    type: "ReLU"
}
#########################################################################################
layer{
	bottom:"s4_branch1_r4_e0"
	top:"interp_upx2"
	name:"interp_upx2"
	type:"Interp"
	interp_param{
		zoom_factor:2
		pad_beg:0
		pad_end:0
	}
}
layer{
	bottom:"s4_branch2_r4_e0"
	top:"interp_upx4"
	name:"interp_upx4"
	type:"Interp"
	interp_param{
		zoom_factor:4
		pad_beg:0
		pad_end:0
	}
}
layer{
	bottom:"s4_branch3_r4_e0"
	top:"interp_upx8"
	name:"interp_upx8"
	type:"Interp"
	interp_param{
		zoom_factor:8
		pad_beg:0
		pad_end:0
	}
}
layer{
	bottom:"s4_branch0_r4_e0"
	bottom:"interp_upx2"
	bottom:"interp_upx4"
	bottom:"interp_upx8"
	top:"concat_4"
	name:"concat_4"
	type:"Concat"
}
layer {
    bottom: "concat_4"
    top: "conv_output_1x1"
    name: "conv_output_1x1"
    type: "Convolution"
    convolution_param {
        num_output: 720 #15C(C=48)
        kernel_size: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    bottom: "conv_output_1x1"
    top: "conv_output_1x1_bn"
    name: "conv_output_1x1_bn"
    type: "CuDNNBatchNorm"
	scale_filler{
		type:"constant"
		value:1
	}
	bias_filler{
		type:"constant"
		value:0
	}
	frozen:false
}
layer {
    bottom: "conv_output_1x1_bn"
    top: "conv_output_1x1_bn"
    name: "conv_output_1x1_bn/relu"
    type: "ReLU"
}
layer {
    bottom: "conv_output_1x1_bn"
    top: "conv_output_seg_1x1"
    name: "conv_output_seg_1x1"
    type: "Convolution"
    convolution_param {
        num_output: 81 #15C(C=48)
        kernel_size: 3
		pad:1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer{
	bottom:"conv_output_seg_1x1"
	top:"interp_up2input_x4"
	name:"interp_up2input_x4"
	type:"Interp"
	interp_param{
		zoom_factor:4
		pad_beg:0
		pad_end:0
	}
}
layer{
	name:"loss"
	type:"SoftmaxWithLoss"
	bottom:"interp_up2input_x4"
	bottom:"label"
	loss_param{
		ignore_label:255
	}
	include:{phase:TRAIN}
}
layer{
	bottom:"data_dim"
	name:"slience"
	type:"Slience"
}